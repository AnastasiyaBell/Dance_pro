{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform\n",
    "\n",
    "distr = platform.dist()[0]\n",
    "\n",
    "PATH = os.path.expanduser('~/datasets/letsdance') if distr == 'Ubuntu' else '/run/media/nast/DATA/letsdance' \n",
    "print(\"dataset path:\", PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"letsdance_split/train/ballet/Et31LySAxf0_020_0266.jpg\"\n",
    "image = misc.imread(os.path.join(PATH, path))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(image.shape, np.amin(image), np.amax(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)\n",
    "    image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "    return image_resized, label\n",
    "\n",
    "# A vector of filenames.\n",
    "TRAIN_PATH = \"letsdance_split/train\"\n",
    "\n",
    "def get_file_names_in_dataset(dataset_path):\n",
    "    classes = os.listdir(os.path.join(PATH, dataset_path))\n",
    "    file_names_in_dataset = {}\n",
    "    for cl in classes:\n",
    "        file_names_in_dataset[cl] = sorted(os.listdir(os.path.join(PATH, dataset_path, cl)))\n",
    "    return file_names_in_dataset\n",
    "\n",
    "\n",
    "def video_name_from_file_name(file_name):\n",
    "    return '_'.join(file_name.split('_')[:-1])\n",
    "\n",
    "\n",
    "def get_num_of_frames_in_videos(list_of_file_names):\n",
    "    videos_names = map(lambda x: video_name_from_file_name(x), list_of_file_names)\n",
    "    return Counter(videos_names)\n",
    " \n",
    "    \n",
    "def select_videos_with_N_frames(list_of_file_names, N):\n",
    "    nfr = get_num_of_frames_in_videos(list_of_file_names)\n",
    "    video_names, _ = zip(*filter(lambda x: x[1] == N, nfr.items()))\n",
    "    return video_names\n",
    "\n",
    "\n",
    "def select_video_names_for_dances(file_names_in_dataset, N):\n",
    "    \"\"\"Selects videos with N frames for each dance so all dances\n",
    "    have equal number of videos. Number of videos for a dance is\n",
    "    the smallest number of videos having N frames among all dances.\"\"\"\n",
    "    selected = {}\n",
    "    for dance_name, list_of_file_names in file_names_in_dataset.items():\n",
    "        videos_with_N_frames = select_videos_with_N_frames(list_of_file_names, N)\n",
    "        selected[dance_name] = videos_with_N_frames\n",
    "    min_num_of_videos_with_N_frames = min(map(len, selected.values()))\n",
    "    for k, v in selected.items():\n",
    "        selected[k] = sorted(v)[:min_num_of_videos_with_N_frames]\n",
    "    return selected\n",
    "\n",
    "\n",
    "def select_file_names_for_work(file_names_in_dataset, N):\n",
    "    video_names = select_video_names_for_dances(file_names_in_dataset, N)\n",
    "    selected_file_names = {}\n",
    "    for dance, list_of_file_names in file_names_in_dataset.items():\n",
    "        selected_file_names[dance] = [fn for fn in list_of_file_names\n",
    "                                      if video_name_from_file_name(fn) in video_names[dance]]\n",
    "    return selected_file_names\n",
    "        \n",
    "    \n",
    "file_names_in_dataset = get_file_names_in_dataset(TRAIN_PATH)\n",
    "\n",
    "print(\"beforer filtering\")\n",
    "for dance, loffn in file_names_in_dataset.items():\n",
    "    print(dance,\n",
    "          'total number of frames: {}'.format(len(loffn)),\n",
    "          'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "          end='\\n\\n', sep='\\n')\n",
    "print('*********\\n\\nAfter filtering')\n",
    "file_names_for_work = select_file_names_for_work(file_names_in_dataset, 300)\n",
    "for dance, loffn in file_names_for_work.items():\n",
    "    print(dance,\n",
    "          'total number of frames: {}'.format(len(loffn)),\n",
    "          'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "          end='\\n\\n', sep='\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "videos_with_300_frames = {}\n",
    "\n",
    "\n",
    "\n",
    "# for k, v in file_names_by_classes.items():\n",
    "#     print(k, len(v), '\\n', v[:1024])\n",
    "# filenames = tf.constant([\"/var/data/image1.jpg\", \"/var/data/image2.jpg\", ...])\n",
    "\n",
    "# # `labels[i]` is the label for the image in `filenames[i].\n",
    "# labels = tf.constant([0, 37, ...])\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "# dataset = dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
