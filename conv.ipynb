{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, platform\n",
    "\n",
    "distr = platform.dist()[0]\n",
    "\n",
    "PATH = os.path.expanduser('~/datasets/letsdance') if distr == 'Ubuntu' else '/run/media/nast/DATA/letsdance'\n",
    "TRAIN_PATH = \"letsdance_split/train\"\n",
    "VALID_PATH = \"letsdance_split/validation\"\n",
    "TEST_PATH = \"letsdance_split/test\"\n",
    "\n",
    "print(\"dataset path:\", PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"letsdance_split/train/ballet/Et31LySAxf0_020_0266.jpg\"\n",
    "image = misc.imread(os.path.join(PATH, path))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(image.shape, np.amin(image), np.amax(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# A vector of filenames.\n",
    "\n",
    "\n",
    "def get_file_names_in_dataset(dataset_path):\n",
    "    classes = os.listdir(os.path.join(PATH, dataset_path))\n",
    "    file_names_in_dataset = {}\n",
    "    for cl in classes:\n",
    "        file_names_in_dataset[cl] = sorted(os.listdir(os.path.join(PATH, dataset_path, cl)))\n",
    "    return file_names_in_dataset\n",
    "\n",
    "\n",
    "def video_name_from_file_name(file_name):\n",
    "    return '_'.join(file_name.split('_')[:-1])\n",
    "\n",
    "\n",
    "def get_num_of_frames_in_videos(list_of_file_names):\n",
    "    videos_names = map(lambda x: video_name_from_file_name(x), list_of_file_names)\n",
    "    return Counter(videos_names)\n",
    " \n",
    "    \n",
    "def select_videos_with_N_frames(list_of_file_names, N):\n",
    "    nfr = get_num_of_frames_in_videos(list_of_file_names)\n",
    "    video_names, _ = zip(*filter(lambda x: x[1] == N, nfr.items()))\n",
    "    return video_names\n",
    "\n",
    "\n",
    "def select_video_names_for_dances(file_names_in_dataset, N):\n",
    "    \"\"\"Selects videos with N frames for each dance so all dances\n",
    "    have equal number of videos. Number of videos for a dance is\n",
    "    the smallest number of videos having N frames among all dances.\"\"\"\n",
    "    selected = {}\n",
    "    for dance_name, list_of_file_names in file_names_in_dataset.items():\n",
    "        videos_with_N_frames = select_videos_with_N_frames(list_of_file_names, N)\n",
    "        selected[dance_name] = videos_with_N_frames\n",
    "    min_num_of_videos_with_N_frames = min(map(len, selected.values()))\n",
    "    for k, v in selected.items():\n",
    "        selected[k] = sorted(v)[:min_num_of_videos_with_N_frames]\n",
    "    return selected\n",
    "\n",
    "\n",
    "def select_file_names_for_work(file_names_in_dataset, N):\n",
    "    video_names = select_video_names_for_dances(file_names_in_dataset, N)\n",
    "    selected_file_names = {}\n",
    "    for dance, list_of_file_names in file_names_in_dataset.items():\n",
    "        selected_file_names[dance] = [fn for fn in list_of_file_names\n",
    "                                      if video_name_from_file_name(fn) in video_names[dance]]\n",
    "    return selected_file_names\n",
    "\n",
    "\n",
    "def prepend_path(file_names_in_dataset, path):\n",
    "    for dance, loffn in file_names_in_dataset.items():\n",
    "        file_names_in_dataset[dance] = list(map(lambda x: os.path.join(path, dance, x), sorted(loffn)))\n",
    "    return file_names_in_dataset\n",
    "        \n",
    "    \n",
    "file_names_in_dataset = get_file_names_in_dataset(TRAIN_PATH)\n",
    "\n",
    "print(\"beforer filtering\")\n",
    "for dance, loffn in file_names_in_dataset.items():\n",
    "    print(dance,\n",
    "          'total number of frames: {}'.format(len(loffn)),\n",
    "          'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "          end='\\n\\n', sep='\\n')\n",
    "print('*********\\n\\nAfter filtering')\n",
    "file_names_for_train = select_file_names_for_work(file_names_in_dataset, 300)\n",
    "dance, loffn = list(file_names_for_train.items())[0]\n",
    "print('total number of frames: {}'.format(len(loffn)),\n",
    "      'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "      end='\\n\\n', sep='\\n')\n",
    "\n",
    "file_names_for_train = prepend_path(file_names_for_train, os.path.join(PATH, TRAIN_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_file_names_in_dataset = get_file_names_in_dataset(VALID_PATH)\n",
    "print(\"beforer filtering\")\n",
    "for dance, loffn in valid_file_names_in_dataset.items():\n",
    "    print(dance,\n",
    "          'total number of frames: {}'.format(len(loffn)),\n",
    "          'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "          end='\\n\\n', sep='\\n')\n",
    "print('*********\\n\\nAfter filtering')\n",
    "valid_file_names_for_work = select_file_names_for_work(valid_file_names_in_dataset, 300)\n",
    "dance, loffn = list(valid_file_names_for_work.items())[0]\n",
    "print('total number of frames: {}'.format(len(loffn)),\n",
    "      'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "      end='\\n\\n', sep='\\n')\n",
    "valid_file_names_for_work = prepend_path(valid_file_names_for_work, os.path.join(PATH, VALID_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_names_in_dataset = get_file_names_in_dataset(TEST_PATH)\n",
    "print(\"beforer filtering\")\n",
    "for dance, loffn in test_file_names_in_dataset.items():\n",
    "    print(dance,\n",
    "          'total number of frames: {}'.format(len(loffn)),\n",
    "          'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "          end='\\n\\n', sep='\\n')\n",
    "print('*********\\n\\nAfter filtering')\n",
    "test_file_names_for_work = select_file_names_for_work(test_file_names_in_dataset, 300)\n",
    "dance, loffn = list(test_file_names_for_work.items())[0]\n",
    "print('total number of frames: {}'.format(len(loffn)),\n",
    "      'number of videos: {}'.format(len(get_num_of_frames_in_videos(loffn))),\n",
    "      end='\\n\\n', sep='\\n')\n",
    "test_file_names_for_work = prepend_path(test_file_names_for_work, os.path.join(PATH, TEST_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "NUM_DANCES = len(file_names_for_train)\n",
    "print(NUM_DANCES)\n",
    "NUM_FRAMES_PER_DANCE_TRAIN = len(list(file_names_for_train.values())[0])\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)\n",
    "    # image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "    return tf.image.resize_images(image_decoded, (224, 224)), label\n",
    "\n",
    "def build_dataset(file_names_for_dataset):\n",
    "    datasets_by_dance = {}\n",
    "\n",
    "    for idx, (dance, loffn) in enumerate(sorted(file_names_for_dataset.items())):\n",
    "        labels = tf.constant([idx] * len(loffn))\n",
    "        filenames = tf.constant(loffn)\n",
    "        datasets_by_dance[dance] = tf.data.Dataset.from_tensor_slices(\n",
    "            (filenames, labels)\n",
    "        ).shuffle(len(loffn)).map(_parse_function)\n",
    "    # print()\n",
    "    dance_zip = tf.data.Dataset.zip(tuple(datasets_by_dance.values()))\n",
    "    # print(dance_zip)\n",
    "    return dance_zip.batch(BATCH_SIZE // NUM_DANCES)\n",
    "\n",
    "train_dataset = build_dataset(file_names_for_train)\n",
    "valid_dataset = build_dataset(valid_file_names_for_work)\n",
    "test_dataset = build_dataset(test_file_names_for_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REG_RATE = 5e-4\n",
    "STDDEV = 0.005\n",
    "\n",
    "\n",
    "def tf_accuracy(preds, labels):\n",
    "    return tf.reduce_sum(\n",
    "        tf.to_float(\n",
    "            tf.equal(\n",
    "                tf.argmax(labels, axis=-1, output_type=tf.int32),\n",
    "                labels\n",
    "            )\n",
    "        )\n",
    "    ) / tf.to_float(tf.shape(labels)[0])\n",
    "\n",
    "\n",
    "def tf_perplexity(preds):\n",
    "    log_preds = tf.log(preds)\n",
    "    inter = tf.exp(tf.reduce_sum((-preds * log_preds), axis=-1))\n",
    "    return tf.reduce_mean(inter)\n",
    "\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                           train_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "inputs, labels = zip(*next_element)\n",
    "\n",
    "inputs = tf.concat(inputs, 0)\n",
    "inputs = tf.to_float(tf.reshape(inputs, tf.concat([tf.shape(inputs)[:-1], [3]], 0)))\n",
    "labels = tf.concat(labels, 0)\n",
    "labels_oh = tf.one_hot(labels, NUM_DANCES, dtype=tf.float32)\n",
    "\n",
    "conv1 = tf.layers.Conv2D(\n",
    "    96,\n",
    "    11,\n",
    "    (4, 4),\n",
    "    activation=tf.nn.relu,\n",
    "    name='conv1',\n",
    "    kernel_initializer=tf.truncated_normal_initializer(stddev=STDDEV),\n",
    ")\n",
    "\n",
    "conv2 = tf.layers.Conv2D(\n",
    "    256,\n",
    "    5,\n",
    "    (1, 1),\n",
    "    activation=tf.nn.relu,\n",
    "    name='conv2',\n",
    "    padding='same',\n",
    "    kernel_initializer=tf.truncated_normal_initializer(stddev=STDDEV),\n",
    ")\n",
    "\n",
    "conv3 = tf.layers.Conv2D(\n",
    "    384,\n",
    "    3,\n",
    "    (1, 1),\n",
    "    activation=tf.nn.relu,\n",
    "    name='conv3', \n",
    "    padding='same',\n",
    "    kernel_initializer=tf.truncated_normal_initializer(stddev=STDDEV),\n",
    ")\n",
    "\n",
    "conv4 = tf.layers.Conv2D(\n",
    "    384,\n",
    "    3,\n",
    "    (1, 1),\n",
    "    activation=tf.nn.relu,\n",
    "    name='conv4',  \n",
    "    padding='same',\n",
    "    kernel_initializer=tf.truncated_normal_initializer(stddev=STDDEV),\n",
    ")\n",
    "\n",
    "conv5 = tf.layers.Conv2D(\n",
    "    256,\n",
    "    3,\n",
    "    (1, 1),\n",
    "    activation=tf.nn.relu,\n",
    "    name='conv5',    \n",
    "    padding='same',\n",
    "    kernel_initializer=tf.truncated_normal_initializer(stddev=STDDEV),\n",
    ")\n",
    "\n",
    "dropout_rate = tf.placeholder(tf.float32)\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "h = tf.reshape(inputs, [-1, 150528])\n",
    "logits = tf.contrib.layers.fully_connected(\n",
    "    h, 10, activation_fn=tf.nn.softmax, weights_initializer=tf.truncated_normal_initializer(stddev=STDDEV)\n",
    ")\n",
    "\n",
    "h = conv1(inputs)\n",
    "h = tf.layers.max_pooling2d(h, 3, 2)\n",
    "h = tf.nn.local_response_normalization(h)\n",
    "\n",
    "h = conv2(h)\n",
    "h = tf.layers.max_pooling2d(h, 3, 2)\n",
    "h = tf.nn.local_response_normalization(h)\n",
    "\n",
    "h = conv3(h)\n",
    "\n",
    "h = conv4(h)\n",
    "\n",
    "h = conv5(h)\n",
    "h = tf.layers.max_pooling2d(h, 3, 2)\n",
    "\n",
    "h = tf.nn.dropout(h, 1. - dropout_rate)\n",
    "\n",
    "h = tf.reshape(h, [-1, 9216])\n",
    "\n",
    "h = tf.contrib.layers.fully_connected(\n",
    "    h, 4096, weights_initializer=tf.truncated_normal_initializer(stddev=STDDEV)\n",
    ")\n",
    "\n",
    "h = tf.nn.dropout(h, 1. - dropout_rate)\n",
    "\n",
    "h = tf.contrib.layers.fully_connected(\n",
    "    h, 4096, weights_initializer=tf.truncated_normal_initializer(stddev=STDDEV)\n",
    ")\n",
    "\n",
    "logits = tf.contrib.layers.fully_connected(\n",
    "    h, 10, activation_fn=tf.nn.softmax, weights_initializer=tf.truncated_normal_initializer(stddev=STDDEV)\n",
    ")\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels_oh)\n",
    "\n",
    "preds = tf.nn.softmax(logits)\n",
    "\n",
    "accuracy = tf_accuracy(logits, labels)\n",
    "\n",
    "perplexity = tf_perplexity(preds)\n",
    "\n",
    "l2_loss = sum(map(tf.nn.l2_loss, tf.get_collection(tf.GraphKeys.WEIGHTS)))\n",
    "\n",
    "opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "train_op = opt.minimize(loss + REG_RATE * l2_loss)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "validation_init_op = iterator.make_initializer(valid_dataset)\n",
    "test_init_op = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE_PATIENCE = 10\n",
    "STOP_PATIENCE = 20\n",
    "STEP_PERIOD = 100\n",
    "INIT_LEARNING_RATE = 0.01\n",
    "DECAY = 0.1\n",
    "\n",
    "train_results_path = 'results/train'\n",
    "valid_results_path = 'results/valid'\n",
    "test_results_path = 'results/test'\n",
    "checkpoint_path = 'checkpoints'\n",
    "\n",
    "for p in [train_results_path, valid_results_path, test_results_path, checkpoint_path]:\n",
    "    if not os.path.isdir(p):\n",
    "        if os.path.isfile(p):\n",
    "            os.remove(p)\n",
    "        os.makedirs(p)\n",
    "        \n",
    "def log(dataset='train', step=None, epoch=None, **kwargs):\n",
    "    appendix = '.txt' if step is None else '_step.txt'\n",
    "    first_value = epoch if step is None else step \n",
    "    for k, v in kwargs.items():\n",
    "        with open(os.path.join('results', dataset, k + appendix), 'w') as f:\n",
    "            if dataset == 'test':\n",
    "                f.write('{}\\n'.format(v))\n",
    "            else:\n",
    "                f.write('{} {}\\n'.format(first_value, v))\n",
    "            \n",
    "            \n",
    "def test(dataset):\n",
    "    init_op = validation_init_op if dataset == 'valid' else test_init_op\n",
    "    sess.run(init_op)\n",
    "    count, accumulated_loss, accumulated_acc, accumulated_perpl = 0, 0, 0, 0\n",
    "    while True:\n",
    "        try:\n",
    "            l, acc, perpl = sess.run([loss, accuracy, perplexity], feed_dict={dropout_rate: 0.})\n",
    "            accumulated_loss += l\n",
    "            accumulated_acc += acc\n",
    "            accumulated_perpl += perpl\n",
    "            count += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    accumulated_loss /= count\n",
    "    accumulated_acc /= count\n",
    "    accumulated_perpl /= count\n",
    "    return accumulated_loss, accumulated_acc, accumulated_perpl\n",
    "\n",
    "step = 0\n",
    "epoch = 0\n",
    "lr_impatience = 0\n",
    "stop_impatience = 0\n",
    "lr = INIT_LEARNING_RATE\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    l, acc, perpl = test('valid')\n",
    "    print('EPOCH {} | step {} | loss {:.4} | accuracy {:.4} | perplexity {:.4}'.format(epoch, step, l, acc, perpl))\n",
    "    log(epoch=epoch, loss=l, accuracy=acc, perplexity=perpl, dataset='valid')\n",
    "    best_loss = l\n",
    "    saver.save(os.path.join(checkpoint_path, 'best'))\n",
    "    while stop_impatience < STOP_PATIENCE:\n",
    "        sess.run(training_init_op)\n",
    "        while True:\n",
    "            try:\n",
    "                _, l, acc, perpl = sess.run(\n",
    "                    [train_op, loss, accuracy, perplexity],\n",
    "                    feed_dict={learning_rate: lr, dropout_rate: 0.5}\n",
    "                )\n",
    "                step += 1\n",
    "                if STEP_PERIOD is not None:\n",
    "                    if step % STEP_PERIOD == 0:\n",
    "                        log(step=step, loss=l, accuracy=acc, perplexity=perpl)\n",
    "                        print('step {} | loss {:.4} | accuracy {:.4}'.format(step, l, acc))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "        epoch += 1\n",
    "        l, acc, perpl = test('valid')\n",
    "        print('EPOCH {} | step {} | loss {:.4} | accuracy {:.4} | perplexity {:.4}'.format(epoch, step, l, acc, perpl))\n",
    "        log(epoch=epoch, loss=l, accuracy=acc, perplexity=perpl, dataset='valid')\n",
    "        if l < best_loss:\n",
    "            lr_impatience, stop_impatience = 0, 0\n",
    "            saver.save(os.path.join(checkpoint_path, 'best'))\n",
    "        else:\n",
    "            lr_impatience += 1\n",
    "            stop_impatience += 1\n",
    "        if lr_impatience >= LEARNING_RATE_PATIENCE:\n",
    "            lr *= DECAY\n",
    "    l, acc, perpl = test('test')\n",
    "    log(loss=l, accuracy=acc, perplexity=perpl, dataset='test')\n",
    "    print('Testing! EPOCH {} | step {} | loss {:.4} | accuracy {:.4} | perplexity {:.4}'.format(epoch, step, l, acc, perpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterator = dance_zip.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(10):\n",
    "        sess.run(iterator.initializer)\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                res = sess.run(next_element)\n",
    "                if i < 5:\n",
    "                    print(i)\n",
    "                    array = res[0][0]\n",
    "                    plt.imshow(array)\n",
    "                    plt.show()\n",
    "                i += 1\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "        print('*' * 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
